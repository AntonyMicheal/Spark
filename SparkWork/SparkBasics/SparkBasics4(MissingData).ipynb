{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qd8nV0LrfGDS",
        "outputId": "336edc30-eacb-40bb-b440-1cc1986bf689"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark py4j"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6mLVv_TfZGG",
        "outputId": "88c4b77e-54d3-4d8d-b173-6208e4b07216"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 43 kB/s \n",
            "\u001b[?25hCollecting py4j\n",
            "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
            "\u001b[K     |████████████████████████████████| 200 kB 49.4 MB/s \n",
            "\u001b[?25h  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 58.3 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845514 sha256=5f3b77df0f8d2344609de55064ce7f7d73cd3c8eedc8e6e56bd4462af25a4733\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/59/f5/79a5bf931714dcd201b26025347785f087370a10a3329a899c\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "KPHfVUsIfjnZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName('miss').getOrCreate()"
      ],
      "metadata": {
        "id": "76eZZu-lf0zv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv(\"/content/drive/MyDrive/SparkWork/SparkDoc/ContainsNull.txt\", inferSchema=True, header=True)"
      ],
      "metadata": {
        "id": "Udc5mG3zgAeC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfhxvQ6gglT3",
        "outputId": "a115e001-215c-4041-d7d1-9c8e55cec996"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+-----+\n",
            "|  Id| Name|Sales|\n",
            "+----+-----+-----+\n",
            "|emp1| John| null|\n",
            "|emp2| null| null|\n",
            "|emp3| null|345.0|\n",
            "|emp4|Cindy|456.0|\n",
            "+----+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Three options in handling a dataset with missing values***\n",
        "\n",
        "* Keep Missing datapoints as null\n",
        "* Droping Missing data with the entire row\n",
        "* Filling data with some value\n",
        "\n",
        "\".na\" methode can be used to fill/ drop / do something of that missing data."
      ],
      "metadata": {
        "id": "Qn3ePUlUg7St"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.na.drop().show() # drops every row that has a missing value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82oNMcWriAyl",
        "outputId": "a8b268ce-a003-470f-d372-0464525bfd40"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+-----+\n",
            "|  Id| Name|Sales|\n",
            "+----+-----+-----+\n",
            "|emp4|Cindy|456.0|\n",
            "+----+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.na.drop(thresh=2).show()#drops every row that has atleast 2 null values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFhZ8dAcguJ3",
        "outputId": "b8de7038-19c9-4798-e2d3-c01521599c27"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+-----+\n",
            "|  Id| Name|Sales|\n",
            "+----+-----+-----+\n",
            "|emp1| John| null|\n",
            "|emp3| null|345.0|\n",
            "|emp4|Cindy|456.0|\n",
            "+----+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Theres also another argument that can be passed into the na.drop() and that is how, and its by default set to \"any\" thats why using drop alone deletes entire rows that have atleast a null value.\n",
        "*   thers another option which is 'all' -> will remove the entire row if only the entire row only consists null values.\n",
        "\n"
      ],
      "metadata": {
        "id": "CqyQ0567imoc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.na.drop(how = \"all\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVJqVOAoiSMN",
        "outputId": "2769d6d6-6dba-4d40-dd0a-ff8b2365d540"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+-----+\n",
            "|  Id| Name|Sales|\n",
            "+----+-----+-----+\n",
            "|emp1| John| null|\n",
            "|emp2| null| null|\n",
            "|emp3| null|345.0|\n",
            "|emp4|Cindy|456.0|\n",
            "+----+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***subsets-> specifies which column are we conidering as a base for removing unwanted data.***"
      ],
      "metadata": {
        "id": "r-2crulcjef7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.na.drop(subset=['sales']).show() # removes the entire row if sales column is missing any value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DeXQ27AjScP",
        "outputId": "a122ade8-7c4f-4c85-aa40-63056df3bc69"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+-----+\n",
            "|  Id| Name|Sales|\n",
            "+----+-----+-----+\n",
            "|emp3| null|345.0|\n",
            "|emp4|Cindy|456.0|\n",
            "+----+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Filling Data***\n",
        "* df.na.fill()\n",
        "* spark can fill in and match up data types.\n",
        "eg: in case if we do df.na.fill('Fill Value').show() => will fill all the missing values that are a string type column\n",
        "* df.na.fill(0).show() will fill 0 insted of null in integer type etc.\n",
        "* We can also specify the column name to wich we are filling the data.\n",
        "eg: df.na.fill('No Name', subset=['name']).show() => results in filling \"No Name\" in only name column.\n"
      ],
      "metadata": {
        "id": "s1gbfabZkXQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.na.fill('Fill Value').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3hsPjQ0kFO9",
        "outputId": "e86e383a-f763-4eb9-b1af-4e3dd17ae1ce"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----------+-----+\n",
            "|  Id|      Name|Sales|\n",
            "+----+----------+-----+\n",
            "|emp1|      John| null|\n",
            "|emp2|Fill Value| null|\n",
            "|emp3|Fill Value|345.0|\n",
            "|emp4|     Cindy|456.0|\n",
            "+----+----------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.na.fill(0).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6ZvtTQflwV3",
        "outputId": "347b804d-4be1-473d-9cce-159da26e7fac"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+-----+\n",
            "|  Id| Name|Sales|\n",
            "+----+-----+-----+\n",
            "|emp1| John|  0.0|\n",
            "|emp2| null|  0.0|\n",
            "|emp3| null|345.0|\n",
            "|emp4|Cindy|456.0|\n",
            "+----+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.na.fill('No Name', subset= ['name']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xF4VPOJlzG-",
        "outputId": "b97157c5-1e3b-4e04-81de-fe4388ed367c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-------+-----+\n",
            "|  Id|   Name|Sales|\n",
            "+----+-------+-----+\n",
            "|emp1|   John| null|\n",
            "|emp2|No Name| null|\n",
            "|emp3|No Name|345.0|\n",
            "|emp4|  Cindy|456.0|\n",
            "+----+-------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Filling mean value***"
      ],
      "metadata": {
        "id": "tYp6_MifmG0T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import mean"
      ],
      "metadata": {
        "id": "dwtpQWkHl99m"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_val = df.select(mean(df['sales'])).collect()"
      ],
      "metadata": {
        "id": "3aush3uZmPI4"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_sales = mean_val[0][0]"
      ],
      "metadata": {
        "id": "kAlQkr0umZYD"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.na.fill(mean_sales, ['sales']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qH1cfl_bmZt9",
        "outputId": "edca3588-ebd4-4139-8497-b0c65bb95b13"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+-----+\n",
            "|  Id| Name|Sales|\n",
            "+----+-----+-----+\n",
            "|emp1| John|400.5|\n",
            "|emp2| null|400.5|\n",
            "|emp3| null|345.0|\n",
            "|emp4|Cindy|456.0|\n",
            "+----+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E9pg5FRlm0W4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}